points(lasso.coef[1],lasso.coef[2],col="blue3")
contour(beta1,beta2,MSE) # Contour
points(fit$coefficients[2],fit$coefficients[3],col="red") # MLE coefficients
points(lasso.coef[1],lasso.coef[2],col="blue3")
# Fit linear model
fit.linear = lm(Comp_Bid~AdX+iPinYou_Bid,data=dataTrainAll)
fit$coefficients[2:3] # MLE coefficients of linear model
# Fit LASSO model
fit.lasso = glmnet(dataTrain2,dataTrainAll$Comp_Bid,family="gaussian",standardize = FALSE,alpha=1)
half_L1norm = 0.5*sum(abs(fit$coefficients[2:3]))
half_L1norm # 0.5*L1 norm of MLE coefficients of linear model
beta_leq_half_L1norm = fit.lasso$beta[,colSums(abs(fit.lasso$beta))<=half_L1norm] # All beta that have L1 norm <= half_L1norm
lasso.coef = beta_leq_half_L1norm[,dim(beta_leq_half_L1norm)[2]] # Beta that have max L1 norm among beta_leq_half_L1norm
lasso.coef
beta1 = seq(-.5,1,length.out=100)
beta2 = seq(-.5,1,length.out=100)
beta = expand.grid(beta1, beta2) # Expand a grid of all combinations of beta1 and beta2
# Function to calculate MSE of a single combination of beta1 and beta2
calc_MSE = function(beta1,beta2){
return(sum((dataTrainAll$Comp_Bid-beta1*dataTrainAll$AdX-beta2*dataTrainAll$iPinYou_Bid)^2))
}
MSE = mapply(calc_MSE,beta[,1],beta[,2]) # Use mapply to apply calc_MSE to all combinations
MSE = matrix(MSE,100,100)
contour(beta1,beta2,MSE) # Contour
points(fit$coefficients[2],fit$coefficients[3],col="red") # MLE coefficients
points(lasso.coef[1],lasso.coef[2],col="blue3")
fit.ridge = glmnet(dataTrain2,dataTrainAll$Comp_Bid,family="gaussian",standardize=FALSE,alpha=0)
# Fit linear model
fit.linear = lm(Comp_Bid~AdX+iPinYou_Bid,data=dataTrainAll)
fit$coefficients[2:3] # MLE coefficients of linear model
# Fit LASSO model
fit.lasso = glmnet(dataTrain2,dataTrainAll$Comp_Bid,family="gaussian",standardize = FALSE,alpha=1)
half_L1norm = 0.5*sum(abs(fit$coefficients[2:3]))
half_L1norm # 0.5*L1 norm of MLE coefficients of linear model
beta_leq_half_L1norm = fit.lasso$beta[,colSums(abs(fit.lasso$beta))<=half_L1norm] # All beta that have L1 norm <= half_L1norm
lasso.coef = beta_leq_half_L1norm[,dim(beta_leq_half_L1norm)[2]] # Beta that have max L1 norm among beta_leq_half_L1norm
lasso.coef
beta1 = seq(-.5,1,length.out=100)
beta2 = seq(-.5,1,length.out=100)
beta = expand.grid(beta1, beta2) # Expand a grid of all combinations of beta1 and beta2
# Function to calculate MSE of a single combination of beta1 and beta2
calc_MSE = function(beta1,beta2){
return(sum((dataTrainAll$Comp_Bid-beta1*dataTrainAll$AdX-beta2*dataTrainAll$iPinYou_Bid)^2))
}
MSE = mapply(calc_MSE,beta[,1],beta[,2]) # Use mapply to apply calc_MSE to all combinations
MSE
beta
MSE = matrix(MSE,100,100)
contour(beta1,beta2,MSE) # Contour
points(fit$coefficients[2],fit$coefficients[3],col="red") # MLE coefficients
points(lasso.coef[1],lasso.coef[2],col="blue3")
fit.ridge = glmnet(dataTrain2,dataTrainAll$Comp_Bid,family="gaussian",standardize=FALSE,alpha=0)
# Fit linear model
fit.linear = lm(Comp_Bid~AdX+iPinYou_Bid,data=dataTrainAll)
fit$coefficients[2:3] # MLE coefficients of linear model
# Fit LASSO model
fit.lasso = glmnet(dataTrain2,dataTrainAll$Comp_Bid,family="gaussian",standardize = FALSE,alpha=1)
half_L1norm = 0.5*sum(abs(fit$coefficients[2:3]))
half_L1norm # 0.5*L1 norm of MLE coefficients of linear model
beta_leq_half_L1norm = fit.lasso$beta[,colSums(abs(fit.lasso$beta))<=half_L1norm] # All beta that have L1 norm <= half_L1norm
lasso.coef = beta_leq_half_L1norm[,dim(beta_leq_half_L1norm)[2]] # Beta that have max L1 norm among beta_leq_half_L1norm
lasso.coef
beta1 = seq(-.5,1,length.out=100)
beta2 = seq(-.5,1,length.out=100)
beta = expand.grid(beta1, beta2) # Expand a grid of all combinations of beta1 and beta2
# Function to calculate MSE of a single combination of beta1 and beta2
calc_MSE = function(beta1,beta2){
return(sum((dataTrainAll$Comp_Bid-beta1*dataTrainAll$AdX-beta2*dataTrainAll$iPinYou_Bid)^2))
}
MSE = mapply(calc_MSE,beta[,1],beta[,2]) # Use mapply to apply calc_MSE to all combinations
MSE
beta
MSE = matrix(MSE,100,100)
MSE
contour(beta1,beta2,MSE) # Contour
points(fit$coefficients[2],fit$coefficients[3],col="red") # MLE coefficients
points(lasso.coef[1],lasso.coef[2],col="blue3")
fit.ridge = glmnet(dataTrain2,dataTrainAll$Comp_Bid,family="gaussian",standardize=FALSE,alpha=0)
# Fit linear model
fit.linear = lm(Comp_Bid~AdX+iPinYou_Bid,data=dataTrainAll)
fit$coefficients[2:3] # MLE coefficients of linear model
# Fit LASSO model
fit.lasso = glmnet(dataTrain2,dataTrainAll$Comp_Bid,family="gaussian",standardize = FALSE,alpha=1)
half_L1norm = 0.5*sum(abs(fit$coefficients[2:3]))
half_L1norm # 0.5*L1 norm of MLE coefficients of linear model
beta_leq_half_L1norm = fit.lasso$beta[,colSums(abs(fit.lasso$beta))<=half_L1norm] # All beta that have L1 norm <= half_L1norm
lasso.coef = beta_leq_half_L1norm[,dim(beta_leq_half_L1norm)[2]] # Beta that have max L1 norm among beta_leq_half_L1norm
lasso.coef
beta1 = seq(-.5,1,length.out=100)
beta2 = seq(-.5,1,length.out=100)
beta = expand.grid(beta1, beta2) # Expand a grid of all combinations of beta1 and beta2
# Function to calculate MSE of a single combination of beta1 and beta2
calc_MSE = function(beta1,beta2){
return(sum((dataTrainAll$Comp_Bid-beta1*dataTrainAll$AdX-beta2*dataTrainAll$iPinYou_Bid)^2))
}
MSE = mapply(calc_MSE,beta[,1],beta[,2]) # Use mapply to apply calc_MSE to all combinations
MSE
beta
MSE = matrix(MSE,100,100,byrow=T)
MSE
contour(beta1,beta2,MSE) # Contour
points(fit$coefficients[2],fit$coefficients[3],col="red") # MLE coefficients
points(lasso.coef[1],lasso.coef[2],col="blue3")
fit.ridge = glmnet(dataTrain2,dataTrainAll$Comp_Bid,family="gaussian",standardize=FALSE,alpha=0)
# Fit linear model
fit.linear = lm(Comp_Bid~AdX+iPinYou_Bid,data=dataTrainAll)
fit$coefficients[2:3] # MLE coefficients of linear model
# Fit LASSO model
fit.lasso = glmnet(dataTrain2,dataTrainAll$Comp_Bid,family="gaussian",standardize = FALSE,alpha=1)
half_L1norm = 0.5*sum(abs(fit$coefficients[2:3]))
half_L1norm # 0.5*L1 norm of MLE coefficients of linear model
beta_leq_half_L1norm = fit.lasso$beta[,colSums(abs(fit.lasso$beta))<=half_L1norm] # All beta that have L1 norm <= half_L1norm
lasso.coef = beta_leq_half_L1norm[,dim(beta_leq_half_L1norm)[2]] # Beta that have max L1 norm among beta_leq_half_L1norm
lasso.coef
beta1 = seq(-.5,1,length.out=100)
beta2 = seq(-.5,1,length.out=100)
beta = expand.grid(beta1, beta2) # Expand a grid of all combinations of beta1 and beta2
# Function to calculate MSE of a single combination of beta1 and beta2
calc_MSE = function(beta1,beta2){
return(sum((dataTrainAll$Comp_Bid-beta1*dataTrainAll$AdX-beta2*dataTrainAll$iPinYou_Bid)^2))
}
MSE = mapply(calc_MSE,beta[,1],beta[,2]) # Use mapply to apply calc_MSE to all combinations
MSE = matrix(MSE,100,100)
contour(beta1,beta2,MSE) # Contour
points(fit$coefficients[2],fit$coefficients[3],col="red") # MLE coefficients
points(lasso.coef[1],lasso.coef[2],col="blue3")
fit.ridge = glmnet(dataTrain2,dataTrainAll$Comp_Bid,family="gaussian",standardize=FALSE,alpha=0)
L1_lasso = sum(abs(lasso.coef))
contour(beta1,beta2,MSE,xlab="beta1",ylab="beta2") # Contour
points(fit$coefficients[2],fit$coefficients[3],col="red") # MLE coefficients
points(lasso.coef[1],lasso.coef[2],col="blue3")
plot(function(x){x+L1_lasso},-L1_lasso,0,add=T,col="green")
plot(function(x){-x-L1_lasso},-L1_lasso,0,add=T,col="green")
plot(function(x){x-L1_lasso},0,L1_lasso,add=T,col="green")
plot(function(x){-x+L1_lasso},0,L1_lasso,add=T,col="green")
fit.ridge = glmnet(dataTrain2,dataTrainAll$Comp_Bid,family="gaussian",standardize=FALSE,alpha=0)
half_L2norm = 0.5*norm(fit$coefficients[2:3], type = "2")
half_L2norm # 0.5*L2 norm of MLE coefficients of linear model
beta_leq_half_L2norm = fit.ridge$beta[,colNorms(fit.ridge$beta)<=half_L2norm] # All beta that have L2 norm <= half_L1norm
install.packages("wordspace")
library(wordspace)
fit.ridge = glmnet(dataTrain2,dataTrainAll$Comp_Bid,family="gaussian",standardize=FALSE,alpha=0)
half_L2norm = 0.5*norm(fit$coefficients[2:3], type = "2")
half_L2norm # 0.5*L2 norm of MLE coefficients of linear model
beta_leq_half_L2norm = fit.ridge$beta[,colNorms(fit.ridge$beta)<=half_L2norm] # All beta that have L2 norm <= half_L1norm
ridge.coef = beta_leq_half_L2norm[,dim(beta_leq_half_L2norm)[2]] # Beta that have max L2 norm among beta_leq_half_L1norm
ridge.coef
beta_leq_half_L2norm
half_L2norm
beta_leq_half_L2norm
half_L2norm
colNorms(beta_leq_half_L2norm)
install.packages("plotrix")
library(wordspace)
library(plotrix)
fit.ridge = glmnet(dataTrain2,dataTrainAll$Comp_Bid,family="gaussian",standardize=FALSE,alpha=0)
half_L2norm = 0.5*norm(fit$coefficients[2:3], type = "2")
half_L2norm # 0.5*L2 norm of MLE coefficients of linear model
beta_leq_half_L2norm = fit.ridge$beta[,colNorms(fit.ridge$beta)<=half_L2norm] # All beta that have L2 norm <= half_L2norm
ridge.coef = beta_leq_half_L2norm[,dim(beta_leq_half_L2norm)[2]] # Beta that have max L2 norm among beta_leq_half_L2norm
ridge.coef
L2_ridge = norm(ridge.coef, type = "2")
contour(beta1,beta2,MSE,xlab="beta1",ylab="beta2") # Contour
points(fit$coefficients[2],fit$coefficients[3],col="red") # MLE coefficients
points(ridge.coef[1],ridge.coef[2],col="blue3") # Ridge coefficients
draw.circle(ridge.coef[1],ridge.coef[2],radius=1)
contour(beta1,beta2,MSE,xlab="beta1",ylab="beta2") # Contour
points(fit$coefficients[2],fit$coefficients[3],col="red") # MLE coefficients
points(ridge.coef[1],ridge.coef[2],col="blue3") # Ridge coefficients
draw.circle(ridge.coef[1],ridge.coef[2],radius=0.5)
contour(beta1,beta2,MSE,xlab="beta1",ylab="beta2") # Contour
points(fit$coefficients[2],fit$coefficients[3],col="red") # MLE coefficients
points(ridge.coef[1],ridge.coef[2],col="blue3") # Ridge coefficients
draw.circle(ridge.coef[1],ridge.coef[2],radius=L2_ridge)
contour(beta1,beta2,MSE,xlab="beta1",ylab="beta2") # Contour
points(fit$coefficients[2],fit$coefficients[3],col="red") # MLE coefficients
points(ridge.coef[1],ridge.coef[2],col="blue3") # Ridge coefficients
draw.circle(0,0,radius=L2_ridge)
contour(beta1,beta2,MSE,xlab="beta1",ylab="beta2") # Contour
points(fit$coefficients[2],fit$coefficients[3],col="red") # MLE coefficients
points(ridge.coef[1],ridge.coef[2],col="blue3") # Ridge coefficients
draw.circle(0,0,radius=0.5)
contour(beta1,beta2,MSE,xlab="beta1",ylab="beta2") # Contour
points(fit$coefficients[2],fit$coefficients[3],col="red") # MLE coefficients
points(ridge.coef[1],ridge.coef[2],col="blue3") # Ridge coefficients
draw.circle(0,0,radius=L2_ridge)
contour(beta1,beta2,MSE,xlab="beta1",ylab="beta2") # Contour
points(fit$coefficients[2],fit$coefficients[3],col="red") # MLE coefficients
points(ridge.coef[1],ridge.coef[2],col="blue3") # Ridge coefficients
draw.circle(0,0,radius=L2_ridge)
plot(function(x){sqrt(L2_ridge-x^2)},-1,1,add=T)
plot(function(x){-sqrt(L2_ridge-x^2)},-1,1,add=T)
contour(beta1,beta2,MSE,xlab="beta1",ylab="beta2") # Contour
points(fit$coefficients[2],fit$coefficients[3],col="red") # MLE coefficients
points(ridge.coef[1],ridge.coef[2],col="blue3") # Ridge coefficients
draw.circle(0,0,radius=L2_ridge)
plot(function(x){sqrt(sum(ridge.coef^2)-x^2)},-1,1,add=T)
plot(function(x){-sqrt(sum(ridge.coef^2)-x^2)},-1,1,add=T)
contour(beta1,beta2,MSE,xlab="beta1",ylab="beta2") # Contour
points(fit$coefficients[2],fit$coefficients[3],col="red") # MLE coefficients
points(ridge.coef[1],ridge.coef[2],col="blue3") # Ridge coefficients
draw.circle(0,0,radius=L2_ridge,add=T)
contour(beta1,beta2,MSE,xlab="beta1",ylab="beta2") # Contour
points(fit$coefficients[2],fit$coefficients[3],col="red") # MLE coefficients
points(ridge.coef[1],ridge.coef[2],col="blue3") # Ridge coefficients
draw.circle(0,0,radius=L2_ridge)
plot(function(x){sqrt(sum(ridge.coef^2)-x^2)},-1,1,add=T)
plot(function(x){-sqrt(sum(ridge.coef^2)-x^2)},-1,1,add=T)
install.packages("DescTools")
library(wordspace)
library(DescTools)
fit.ridge = glmnet(dataTrain2,dataTrainAll$Comp_Bid,family="gaussian",standardize=FALSE,alpha=0)
half_L2norm = 0.5*norm(fit$coefficients[2:3], type = "2")
half_L2norm # 0.5*L2 norm of MLE coefficients of linear model
beta_leq_half_L2norm = fit.ridge$beta[,colNorms(fit.ridge$beta)<=half_L2norm] # All beta that have L2 norm <= half_L2norm
ridge.coef = beta_leq_half_L2norm[,dim(beta_leq_half_L2norm)[2]] # Beta that have max L2 norm among beta_leq_half_L2norm
ridge.coef
L2_ridge = norm(ridge.coef, type = "2")
contour(beta1,beta2,MSE,xlab="beta1",ylab="beta2") # Contour
points(fit$coefficients[2],fit$coefficients[3],col="red") # MLE coefficients
points(ridge.coef[1],ridge.coef[2],col="blue3") # Ridge coefficients
DrawEllipse(0,0, radius.x = L2_ridge, radius.y = L2_ridge)
plot(function(x){sqrt(sum(ridge.coef^2)-x^2)},-1,1,add=T)
plot(function(x){-sqrt(sum(ridge.coef^2)-x^2)},-1,1,add=T)
contour(beta1,beta2,MSE,xlab="beta1",ylab="beta2") # Contour
points(fit$coefficients[2],fit$coefficients[3],col="red") # MLE coefficients
points(ridge.coef[1],ridge.coef[2],col="blue3") # Ridge coefficients
DrawEllipse(0,0, radius.x = L2_ridge, radius.y = L2_ridge,border="green")
contour(beta1,beta2,MSE,xlab="beta1",ylab="beta2") # Contour
points(fit$coefficients[2],fit$coefficients[3],col="red") # MLE coefficients
points(ridge.coef[1],ridge.coef[2],col="blue3") # Ridge coefficients
DrawEllipse(0,0, radius.x = L2_ridge, radius.y = L2_ridge,border="green",col =NA)
contour(beta1,beta2,MSE,xlab="beta1",ylab="beta2") # Contour
points(fit$coefficients[2],fit$coefficients[3],col="red") # MLE coefficients
points(ridge.coef[1],ridge.coef[2],col="blue3") # Ridge coefficients
DrawEllipse(0,0, radius.x = L2_ridge, radius.y = L2_ridge,border="green",col =NA)
plot(function(x){sqrt(sum(ridge.coef^2)-x^2)},-1,1,add=T)
plot(function(x){-sqrt(sum(ridge.coef^2)-x^2)},-1,1,add=T)
contour(beta1,beta2,MSE,xlab="beta1",ylab="beta2") # Contour
points(fit$coefficients[2],fit$coefficients[3],col="red") # MLE coefficients
points(ridge.coef[1],ridge.coef[2],col="blue3") # Ridge coefficients
DrawEllipse(0,0, radius.x = L2_ridge, radius.y = L2_ridge,border="green",col =NA)
# Fit linear model
fit.linear = lm(Comp_Bid~AdX+iPinYou_Bid,data=dataTrainAll)
fit$coefficients[2:3] # MLE coefficients of linear model
# Fit LASSO model
fit.lasso = glmnet(dataTrain2,dataTrainAll$Comp_Bid,family="gaussian",standardize = FALSE,alpha=1)
half_L1norm = 0.5*sum(abs(fit$coefficients[2:3]))
half_L1norm # 0.5*L1 norm of MLE coefficients of linear model
beta_leq_half_L1norm = fit.lasso$beta[,colSums(abs(fit.lasso$beta))<=half_L1norm] # All beta that have L1 norm <= half_L1norm
lasso.coef = beta_leq_half_L1norm[,dim(beta_leq_half_L1norm)[2]] # Beta that have max L1 norm among beta_leq_half_L1norm
lasso.coef
beta1 = seq(-.5,1,length.out=100)
beta2 = seq(-.5,1,length.out=100)
beta = expand.grid(beta1, beta2) # Expand a grid of all combinations of beta1 and beta2
# Function to calculate MSE of a single combination of beta1 and beta2
calc_MSE = function(beta1,beta2){
return(sum((dataTrainAll$Comp_Bid-beta1*dataTrainAll$AdX-beta2*dataTrainAll$iPinYou_Bid)^2))
}
MSE = mapply(calc_MSE,beta[,1],beta[,2]) # Use mapply to apply calc_MSE to all combinations
MSE = matrix(MSE,100,100)
L1_lasso = sum(abs(lasso.coef))
contour(beta1,beta2,MSE,xlab="beta1",ylab="beta2") # Contour
points(fit$coefficients[2],fit$coefficients[3],col="red") # MLE coefficients
points(lasso.coef[1],lasso.coef[2],col="blue3") # LASSO coefficients
plot(function(x){x+L1_lasso},-L1_lasso,0,add=T,col="green")
plot(function(x){-x-L1_lasso},-L1_lasso,0,add=T,col="green")
plot(function(x){x-L1_lasso},0,L1_lasso,add=T,col="green")
plot(function(x){-x+L1_lasso},0,L1_lasso,add=T,col="green")
# Ridge Regression part
library(wordspace)
library(DescTools)
fit.ridge = glmnet(dataTrain2,dataTrainAll$Comp_Bid,family="gaussian",standardize=FALSE,alpha=0)
half_L2norm = 0.5*norm(fit$coefficients[2:3], type = "2")
half_L2norm # 0.5*L2 norm of MLE coefficients of linear model
beta_leq_half_L2norm = fit.ridge$beta[,colNorms(fit.ridge$beta)<=half_L2norm] # All beta that have L2 norm <= half_L2norm
ridge.coef = beta_leq_half_L2norm[,dim(beta_leq_half_L2norm)[2]] # Beta that have max L2 norm among beta_leq_half_L2norm
ridge.coef
L2_ridge = norm(ridge.coef, type = "2")
contour(beta1,beta2,MSE,xlab="beta1",ylab="beta2") # Contour
points(fit$coefficients[2],fit$coefficients[3],col="red") # MLE coefficients
points(ridge.coef[1],ridge.coef[2],col="blue3") # Ridge coefficients
DrawEllipse(0,0, radius.x = L2_ridge, radius.y = L2_ridge,border="green",col =NA)
beta_leq_half_L2norm
norm(c(-0.1765613,0.5160305),type = "2")
half_L2norm
norm(c(-0.1765613,0.5160305),type = "2")
norm(ridge.coef,type="2")
# Fit linear model
fit.linear = lm(Comp_Bid~AdX+iPinYou_Bid,data=dataTrainAll)
fit$coefficients[2:3] # MLE coefficients of linear model
# Fit LASSO model
fit.lasso = glmnet(dataTrain2,dataTrainAll$Comp_Bid,family="gaussian",standardize = FALSE,alpha=1)
half_L1norm = 0.5*sum(abs(fit$coefficients[2:3]))
half_L1norm # 0.5*L1 norm of MLE coefficients of linear model
beta_leq_half_L1norm = fit.lasso$beta[,colSums(abs(fit.lasso$beta))<=half_L1norm] # All beta that have L1 norm <= half_L1norm
lasso.coef = beta_leq_half_L1norm[,dim(beta_leq_half_L1norm)[2]] # Beta that have max L1 norm among beta_leq_half_L1norm
lasso.coef
beta1 = seq(-.5,1,length.out=100)
beta2 = seq(-.5,1,length.out=100)
beta = expand.grid(beta1, beta2) # Expand a grid of all combinations of beta1 and beta2
# Function to calculate MSE of a single combination of beta1 and beta2
calc_MSE = function(beta1,beta2){
return(sum((dataTrainAll$Comp_Bid-beta1*dataTrainAll$AdX-beta2*dataTrainAll$iPinYou_Bid)^2))
}
MSE = mapply(calc_MSE,beta[,1],beta[,2]) # Use mapply to apply calc_MSE to all combinations
MSE = matrix(MSE,100,100)
L1_lasso = sum(abs(lasso.coef))
contour(beta1,beta2,MSE,xlab="beta1",ylab="beta2") # Contour
points(fit$coefficients[2],fit$coefficients[3],col="red") # MLE coefficients
points(lasso.coef[1],lasso.coef[2],col="blue3") # LASSO coefficients
plot(function(x){x+L1_lasso},-L1_lasso,0,add=T,col="green")
plot(function(x){-x-L1_lasso},-L1_lasso,0,add=T,col="green")
plot(function(x){x-L1_lasso},0,L1_lasso,add=T,col="green")
plot(function(x){-x+L1_lasso},0,L1_lasso,add=T,col="green")
# Ridge Regression part
library(wordspace)
library(DescTools)
fit.ridge = glmnet(dataTrain2,dataTrainAll$Comp_Bid,family="gaussian",standardize=FALSE,alpha=0)
half_L2norm = 0.5*norm(fit$coefficients[2:3], type = "2")
half_L2norm # 0.5*L2 norm of MLE coefficients of linear model
beta_leq_half_L2norm = fit.ridge$beta[,colNorms(fit.ridge$beta)<=half_L2norm] # All beta that have L2 norm <= half_L2norm
ridge.coef = beta_leq_half_L2norm[,dim(beta_leq_half_L2norm)[2]] # Beta that have max L2 norm among beta_leq_half_L2norm
ridge.coef
L2_ridge = norm(ridge.coef, type = "2")
contour(beta1,beta2,MSE,xlab="beta1",ylab="beta2") # Contour
points(fit$coefficients[2],fit$coefficients[3],col="red") # MLE coefficients
points(ridge.coef[1],ridge.coef[2],col="blue3") # Ridge coefficients
DrawEllipse(0,0, radius.x = L2_ridge, radius.y = L2_ridge,border="green",col =NA)
LIGO = read.table("LIGO.Hanford.Data.txt", header=TRUE)
head(LIGO)
set.seed(10)
LIGO = read.table("LIGO.Hanford.Data.txt", header=TRUE)
head(LIGO)
set.seed(10)
LIGO = read.table("LIGO.Hanford.Data.txt", header=F)
head(LIGO)
C.r1 = sqrt(LIGO[,1])
C.r1
C.r1 = sqrt(LIGO[,1]) # Row 1 of C
C = sqrt(2/LIGO[,1])*cos()
C.r1 = sqrt(LIGO[,1]) # Row 1 of C
n_row = nrow(LIGO)
n_row
C.r1 = sqrt(LIGO[,1]) # Row 1 of C
n_row = nrow(LIGO)
C = matrix(,n_row-1,n_row)
C = rbind(C.r1,C)
C.r1 = sqrt(LIGO[,1]) # Row 1 of C
n_row = nrow(LIGO)
C = matrix(,n_row-1,n_row)
C = rbind(C.r1,C)
C
C.r1 = sqrt(LIGO[,1]) # Row 1 of C
n_row = nrow(LIGO)
C = matrix(,n_row-1,n_row)
C = rbind(C,C.r1)
C
C.r1 = sqrt(LIGO[,1]) # Row 1 of C
n_row = nrow(LIGO)
C = matrix(,n_row-1,n_row)
C = rbind(C,C.r1)
sum(C)
C.r1 = sqrt(LIGO[,1]) # Row 1 of C
n_row = nrow(LIGO)
C = matrix(,n_row-1,n_row)
C = rbind(C,C.r1)
C.r1
n_row = nrow(LIGO)
sqrt_n_row = sqrt(n_row)
C = matrix(,n_row,n_row)
for (j in 1:n_row){
for (k in 1:n_row){
if (j=1){
n_row = nrow(LIGO)
sqrt_n_row = sqrt(n_row)
C = matrix(,n_row,n_row)
for (j in 1:n_row){
for (k in 1:n_row){
if (j==1){
C[j,k] = sqrt_n_row
}
else {
C[j,k] = sqrt(2/n_row)*cos(pi*(2*k-1)*(j-1))
}
}
}
C
n_row = nrow(LIGO)
sqrt_n_row = sqrt(n_row)
C = matrix(,nrow=n_row,ncol=n_row)
for (j in 1:n_row){
for (k in 1:n_row){
if (j==1){
C[j,k] = sqrt_n_row
}
else {
C[j,k] = sqrt(2/n_row)*cos(pi*(2*k-1)*(j-1))
}
}
}
C
n_row = nrow(LIGO)
sqrt_n_row = sqrt(n_row)
C = matrix(, nrow = n_row, ncol = n_row)
for (j in 1:n_row){
for (k in 1:n_row){
if (j==1){
C[j,k] = sqrt_n_row
}
else {
C[j,k] = sqrt(2/n_row)*cos(pi*(2*k-1)*(j-1))
}
}
}
C
n_row = nrow(LIGO)
sqrt_n_row = sqrt(n_row)
C = matrix(0, nrow = n_row, ncol = n_row)
for (j in 1:n_row){
for (k in 1:n_row){
if (j==1){
C[j,k] = sqrt_n_row
}
else {
C[j,k] = sqrt(2/n_row)*cos(pi*(2*k-1)*(j-1))
}
}
}
C
n_row = nrow(LIGO)
sqrt_n_row = sqrt(n_row)
n_row
C = matrix(0, nrow = n_row, ncol = n_row)
for (j in 1:n_row){
for (k in 1:n_row){
if (j==1){
C[j,k] = sqrt_n_row
}
else {
C[j,k] = sqrt(2/n_row)*cos(pi*(2*k-1)*(j-1))
}
}
}
C
n_row = nrow(LIGO)
sqrt_n_row = sqrt(n_row)
C = matrix(, nrow = n_row, ncol = n_row)
for (j in 1:n_row){
for (k in 1:n_row){
if (j==1){
C[j,k] = sqrt_n_row
}
else {
C[j,k] = sqrt(2/n_row)*cos(pi*(2*k-1)*(j-1))
}
}
}
C[1,1]
C
C[10,10]
View(C)
n_row = nrow(LIGO)
sqrt_n_row = sqrt(n_row)
C = matrix(, nrow = n_row, ncol = n_row)
for (j in 1:n_row){
for (k in 1:n_row){
if (j==1){
C[j,k] = sqrt_n_row
}
else {
C[j,k] = sqrt(2/n_row)*cos(pi*(2*k-1)*(j-1)/(2*n_row))
}
}
}
C[10,10]
View(C)
n_row = nrow(LIGO)
sqrt_n_row = sqrt(n_row)
C = matrix(, nrow = n_row, ncol = n_row)
for (j in 1:n_row){
for (k in 1:n_row){
if (j==1){
C[j,k] = sqrt_n_row
}
else {
C[j,k] = sqrt(2/n_row)*cos(pi*(2*k-1)*(j-1)/(2*n_row))
}
}
}
cv.lasso = cv.glmnet(C,LIGO[1],alpha=1,nfolds = 10)
n_row = nrow(LIGO)
sqrt_n_row = sqrt(n_row)
C = matrix(, nrow = n_row, ncol = n_row)
for (j in 1:n_row){
for (k in 1:n_row){
if (j==1){
C[j,k] = sqrt_n_row
}
else {
C[j,k] = sqrt(2/n_row)*cos(pi*(2*k-1)*(j-1)/(2*n_row))
}
}
}
cv.lasso = cv.glmnet(C,as.matrix(LIGO[1]),alpha=1,nfolds = 10)
w_hat = cv.lasso$beta[,cv.lasso$lambda.min]
w_hat
cv.lasso$beta
cv.lasso = cv.glmnet(C,as.matrix(LIGO[2]),alpha=1,nfolds = 10)
w_hat = cv.lasso$beta[,cv.lasso$lambda.min]
cv.lasso$beta
cv.lasso = cv.glmnet(C,as.matrix(LIGO[2]),alpha=1,nfolds = 10)
