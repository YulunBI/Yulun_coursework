{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YvbkHQQkSzdi"
   },
   "source": [
    "# CSCC11 - Introduction to Machine Learning, Fall 2022, Assignment 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "pK-Wu4hfz97-"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "import statistics\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "e5f5zgrD0DHJ"
   },
   "outputs": [],
   "source": [
    "#TO-DO\n",
    "\"\"\"\n",
    "Read the csv file into a DataFrame - df\n",
    "\"\"\"\n",
    "df = pd.read_csv('Admission_Predict.csv', sep=',', header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "UlYEmMORp1nv"
   },
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Serial No.</th>\n      <th>GRE Score</th>\n      <th>TOEFL Score</th>\n      <th>University Rating</th>\n      <th>SOP</th>\n      <th>LOR</th>\n      <th>CGPA</th>\n      <th>Research</th>\n      <th>Chance of Admit</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>337</td>\n      <td>118</td>\n      <td>4</td>\n      <td>4.5</td>\n      <td>4.5</td>\n      <td>9.65</td>\n      <td>1</td>\n      <td>0.92</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>324</td>\n      <td>107</td>\n      <td>4</td>\n      <td>4.0</td>\n      <td>4.5</td>\n      <td>8.87</td>\n      <td>1</td>\n      <td>0.76</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>316</td>\n      <td>104</td>\n      <td>3</td>\n      <td>3.0</td>\n      <td>3.5</td>\n      <td>8.00</td>\n      <td>1</td>\n      <td>0.72</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>322</td>\n      <td>110</td>\n      <td>3</td>\n      <td>3.5</td>\n      <td>2.5</td>\n      <td>8.67</td>\n      <td>1</td>\n      <td>0.80</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>314</td>\n      <td>103</td>\n      <td>2</td>\n      <td>2.0</td>\n      <td>3.0</td>\n      <td>8.21</td>\n      <td>0</td>\n      <td>0.65</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>395</th>\n      <td>396</td>\n      <td>324</td>\n      <td>110</td>\n      <td>3</td>\n      <td>3.5</td>\n      <td>3.5</td>\n      <td>9.04</td>\n      <td>1</td>\n      <td>0.82</td>\n    </tr>\n    <tr>\n      <th>396</th>\n      <td>397</td>\n      <td>325</td>\n      <td>107</td>\n      <td>3</td>\n      <td>3.0</td>\n      <td>3.5</td>\n      <td>9.11</td>\n      <td>1</td>\n      <td>0.84</td>\n    </tr>\n    <tr>\n      <th>397</th>\n      <td>398</td>\n      <td>330</td>\n      <td>116</td>\n      <td>4</td>\n      <td>5.0</td>\n      <td>4.5</td>\n      <td>9.45</td>\n      <td>1</td>\n      <td>0.91</td>\n    </tr>\n    <tr>\n      <th>398</th>\n      <td>399</td>\n      <td>312</td>\n      <td>103</td>\n      <td>3</td>\n      <td>3.5</td>\n      <td>4.0</td>\n      <td>8.78</td>\n      <td>0</td>\n      <td>0.67</td>\n    </tr>\n    <tr>\n      <th>399</th>\n      <td>400</td>\n      <td>333</td>\n      <td>117</td>\n      <td>4</td>\n      <td>5.0</td>\n      <td>4.0</td>\n      <td>9.66</td>\n      <td>1</td>\n      <td>0.95</td>\n    </tr>\n  </tbody>\n</table>\n<p>400 rows × 9 columns</p>\n</div>",
      "text/plain": "     Serial No.  GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  \\\n0             1        337          118                  4  4.5   4.5  9.65   \n1             2        324          107                  4  4.0   4.5  8.87   \n2             3        316          104                  3  3.0   3.5  8.00   \n3             4        322          110                  3  3.5   2.5  8.67   \n4             5        314          103                  2  2.0   3.0  8.21   \n..          ...        ...          ...                ...  ...   ...   ...   \n395         396        324          110                  3  3.5   3.5  9.04   \n396         397        325          107                  3  3.0   3.5  9.11   \n397         398        330          116                  4  5.0   4.5  9.45   \n398         399        312          103                  3  3.5   4.0  8.78   \n399         400        333          117                  4  5.0   4.0  9.66   \n\n     Research  Chance of Admit   \n0           1              0.92  \n1           1              0.76  \n2           1              0.72  \n3           1              0.80  \n4           0              0.65  \n..        ...               ...  \n395         1              0.82  \n396         1              0.84  \n397         1              0.91  \n398         0              0.67  \n399         1              0.95  \n\n[400 rows x 9 columns]"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Print the DataFrame\n",
    "\"\"\"\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "qG0T29UBp1nw"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400\n",
      "['Serial No.' 'GRE Score' 'TOEFL Score' 'University Rating' 'SOP' 'LOR '\n",
      " 'CGPA' 'Research' 'Chance of Admit ']\n"
     ]
    }
   ],
   "source": [
    "#TO-DO\n",
    "\"\"\"\n",
    "Print the length of the DataFrame.\n",
    "Print the column names of the DataFrame.\n",
    "\"\"\"\n",
    "print(df.shape[0])\n",
    "print(df.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "eI7SRu_kp1nx"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400, 8)\n",
      "(400, 1)\n"
     ]
    }
   ],
   "source": [
    "#TO-DO\n",
    "\"\"\"\n",
    "Define an “X” array that would hold our independent features for regression purposes.  \n",
    "Define a \"Y\" array that would hold our target variable.\n",
    "\n",
    "Print the shape of both the arrays.\n",
    "\"\"\"\n",
    "X = df.iloc[:,:-1]\n",
    "Y = df.iloc[:,-1].values.reshape(X.shape[0],1)\n",
    "print(X.shape)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q5xnt6Wfp1ny"
   },
   "source": [
    "## Split the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "JPZ5RlYQp1ny"
   },
   "outputs": [],
   "source": [
    "#TO-DO\n",
    "\"\"\"\n",
    "Split the dataset into train dataset and test dataset.\n",
    "Set the random state to any number in order to maintain consistency while generating random numbers over several runs.\n",
    "\"\"\"\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eY7EqYsZp1nz"
   },
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "hu8lbAnVp1nz"
   },
   "outputs": [],
   "source": [
    "#TO-DO\n",
    "def find_optimal_parameters(x, y):\n",
    "    \"\"\" Compute closed form solution for linear regression!\n",
    "    Optimal weight w* in linear regression is given by w* = (X^T X)^(-1) X^T Y\n",
    "    \n",
    "    Args:\n",
    "    - x (ndarray (Shape: (N, D))): A NxD matrix corresponding to the inputs.\n",
    "    - y (ndarray (Shape: (N, 1))): A N-column vector corresponding to the outputs given the inputs.\n",
    "    \n",
    "    Output:\n",
    "    - w (ndarray (Shape: (D, 1))): A D-column vector corresponding to the bias and weights of the linear model.\n",
    "    \"\"\"\n",
    "    # Pad 1's for the bias term, Why?\n",
    "    x = np.hstack((np.ones((x.shape[0], 1)), x))\n",
    "\n",
    "    # Note that we could use pseudoinverse here instead: np.linalg.pinv\n",
    "    # @ is alias for matmul\n",
    "    p1 = np.linalg.pinv(np.transpose(x) @ x)# (X^T X) inverse\n",
    "    p2 = np.transpose(x) @ y # X^T Y\n",
    "    w = p1 @ p2\n",
    "    return w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hef0J8wPp1nz"
   },
   "source": [
    "### Train linear regression model using training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "b2tMQBXYp1n0"
   },
   "outputs": [],
   "source": [
    "#TO-DO\n",
    "def get_pred_Y(trained_w, X_pred):\n",
    "    \"\"\" Return predicted Y\n",
    "    Args:\n",
    "    - trained_w (ndarray (Shape: (D+1, 1))): A (D+1)x1 column vector containing linear regression weights.\n",
    "    - X_pred (ndarray (Shape: (N, D))): A NxD matrix corresponding to the prediction inputs.\n",
    "    \n",
    "    Output:\n",
    "    - pred_Y (ndarray (Shape: (N, 1))): A Nx1 column vector corresponding to the predicted outputs.\n",
    "    \"\"\"\n",
    "    pad_Y     = np.hstack((np.ones((X_pred.shape[0], 1)), X_pred))\n",
    "    pred_Y    = pad_Y @ trained_w\n",
    "    return pred_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "NvJEIbPFp1n0"
   },
   "outputs": [],
   "source": [
    "#TO-DO\n",
    "def get_mae(Y_truth, Y_pred):\n",
    "    \"\"\" Return Mean absolute error\n",
    "    Args:\n",
    "    - Y_truth (ndarray (Shape: (N, 1))): A Nx1 column vector corresponding to the actual outputs.\n",
    "    - Y_pred (ndarray (Shape: (N, 1))): A Nx1 column vector corresponding to the predicted outputs.\n",
    "    \n",
    "    Output:\n",
    "    - MSE (ndarray (Shape: (1,))).\n",
    "    \"\"\"\n",
    "    'check if both inputs are of the same shape'\n",
    "    if (Y_truth.shape != Y_pred.shape):\n",
    "        print(\"Warming!\",Y_truth.shape, Y_pred.shape)\n",
    "        return -1\n",
    "    mae    = np.sum(np.absolute(Y_truth - Y_pred))/Y_pred.shape[0]\n",
    "    return mae\n",
    "\n",
    "def get_mse(Y_truth, Y_pred):\n",
    "    \"\"\" Return Mean squared error\n",
    "    Args:\n",
    "    - Y_truth (ndarray (Shape: (N, 1))): A Nx1 column vector corresponding to the actual outputs.\n",
    "    - Y_pred (ndarray (Shape: (N, 1))): A Nx1 column vector corresponding to the predicted outputs.\n",
    "    \n",
    "    Output:\n",
    "    - MSE (ndarray (Shape: (1,))).\n",
    "    \"\"\"\n",
    "    'check if both inputs are of the same shape'\n",
    "    if (Y_truth.shape != Y_pred.shape):\n",
    "        print(\"Warming!\",Y_truth.shape, Y_pred.shape)\n",
    "        return -1\n",
    "    mse    = np.sum(np.square(Y_truth - Y_pred))/Y_pred.shape[0]\n",
    "    return mse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ihQlEbDzp1n1"
   },
   "source": [
    "### Get predictions on train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "ycC9grI0rKkn"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.37559131e+00]\n",
      " [ 1.31968750e-04]\n",
      " [ 2.29768983e-03]\n",
      " [ 2.57080482e-03]\n",
      " [ 1.10083142e-02]\n",
      " [-7.48574188e-04]\n",
      " [ 2.06096386e-02]\n",
      " [ 1.11998704e-01]\n",
      " [ 1.24114883e-02]]\n"
     ]
    }
   ],
   "source": [
    "w_optimal = find_optimal_parameters(X_train, Y_train)\n",
    "print(w_optimal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "jntfL_s7p1n1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train error (MSE):  0.0033854592598648427\n",
      "train error (MAE):  0.042913770093862096\n"
     ]
    }
   ],
   "source": [
    "pred_Y    = get_pred_Y(w_optimal, X_train)\n",
    "print('train error (MSE): ', get_mse(Y_train, pred_Y))\n",
    "print('train error (MAE): ', get_mae(Y_train, pred_Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PrQ5lClCp1n1"
   },
   "source": [
    "### Get predictions and performance on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "Od4gUr8jp1n1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test error (MSE)::  0.00452619068784237\n",
      "test error (MAE):  0.04690716026358087\n"
     ]
    }
   ],
   "source": [
    "pred_Y    = get_pred_Y(w_optimal, X_test)\n",
    "print('test error (MSE):: ', get_mse(Y_test, pred_Y))\n",
    "print('test error (MAE): ', get_mae(Y_test, pred_Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VsVtfDC12Rh_"
   },
   "source": [
    "# Silouette Coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "MBUC-6gR2Vh7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K =  2 , silhouetter score =  0.6116585331973866\n",
      "K =  3 , silhouetter score =  0.5439603909593356\n",
      "K =  4 , silhouetter score =  0.5244267025733921\n",
      "K =  5 , silhouetter score =  0.48291167894004466\n",
      "K =  6 , silhouetter score =  0.46041825313273566\n",
      "K =  7 , silhouetter score =  0.4429618727806108\n",
      "K =  8 , silhouetter score =  0.41809916954838816\n",
      "K =  9 , silhouetter score =  0.3988447362932631\n",
      "K =  10 , silhouetter score =  0.3826793259548973\n"
     ]
    }
   ],
   "source": [
    "#TO-DO\n",
    "n_silhouette = []\n",
    "\n",
    "kmeans_kwargs= {\n",
    "    \"init\":\"k-means++\",\n",
    "    \"n_init\":30,\n",
    "    \"max_iter\":250,\n",
    "    \"random_state\":2\n",
    "}\n",
    "\n",
    "\"\"\"\n",
    "Perform the following steps:\n",
    "\n",
    "1. Loop over the various possible K values you wish to test\n",
    "2. Initialize a K means object.\n",
    "3. Fit the training data on the K means object.\n",
    "4. Use the silhouette score method available from the sklearn metrics.\n",
    "5. Append the score to the silhouetter_coefficients list.\n",
    "6. Display the the silhouette coefficient associated with each value of K.\n",
    "\"\"\"\n",
    "for K in range(2,11):\n",
    "    kmeans = KMeans(n_clusters=K, init=kmeans_kwargs[\"init\"], n_init=kmeans_kwargs[\"n_init\"], \n",
    "    max_iter=kmeans_kwargs[\"max_iter\"], random_state = kmeans_kwargs[\"random_state\"])\n",
    "    kmeans.fit_predict(X_train)\n",
    "    score = silhouette_score(X_train, kmeans.labels_)\n",
    "    n_silhouette.append(score)\n",
    "    print(\"K = \",K, \", silhouetter score = \",score)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0H6Djcju85JN"
   },
   "source": [
    "# K Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "6BvShiJG88NZ"
   },
   "outputs": [],
   "source": [
    "kmeans = KMeans(\n",
    "    init=\"k-means++\",\n",
    "    n_clusters = 2, #Input the value you configured using the Silhouette coefficient analysis.\n",
    "    n_init=30,\n",
    "    max_iter=250,\n",
    "    random_state=2\n",
    ")\n",
    "\n",
    "#TO-DO\n",
    "# Fit to the training data\n",
    "kmeans.fit_predict(X_train)\n",
    "\n",
    "#TO-DO\n",
    "# Add the features and the training data you used to the variable below.\n",
    "training_df_clustered = X_train.copy()\n",
    "\n",
    "#TO-DO\n",
    "# Predict clusters for the training data\n",
    "train_cluster = kmeans.predict(X_train)\n",
    "\n",
    "#TO-DO\n",
    "# Add the target and predicted clusters to the training DataFrame\n",
    "training_df_clustered.insert(loc=8,column=\"Chance of Admit\",value=Y_train)\n",
    "training_df_clustered.insert(loc=9,column=\"cluster\",value=train_cluster)\n",
    "\n",
    "\n",
    "#TO-DO\n",
    "# Set the number of clusters based on the silhouette coefficient analysis\n",
    "number_cluster = kmeans.cluster_centers_.shape[0]\n",
    "\n",
    "X_train_clusters_df = []\n",
    "for i in range(number_cluster):\n",
    "    X_train_clusters_df.append(training_df_clustered[training_df_clustered['cluster']==i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[     Serial No.  GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  \\\n",
      "399         400        333          117                  4  5.0   4.0  9.66   \n",
      "279         280        304          102                  2  3.0   4.0  8.73   \n",
      "260         261        327          108                  5  5.0   3.5  9.13   \n",
      "380         381        322          104                  3  3.5   4.0  8.84   \n",
      "360         361        322          110                  3  4.0   5.0  8.64   \n",
      "..          ...        ...          ...                ...  ...   ...   ...   \n",
      "395         396        324          110                  3  3.5   3.5  9.04   \n",
      "221         222        316          110                  3  3.5   4.0  8.56   \n",
      "369         370        301           98                  1  2.0   3.0  8.03   \n",
      "320         321        317          106                  3  4.0   3.5  8.50   \n",
      "265         266        313          102                  3  2.5   2.5  8.68   \n",
      "\n",
      "     Research  Chance of Admit  cluster  \n",
      "399         1             0.95        0  \n",
      "279         0             0.67        0  \n",
      "260         1             0.87        0  \n",
      "380         1             0.78        0  \n",
      "360         1             0.85        0  \n",
      "..        ...              ...      ...  \n",
      "395         1             0.82        0  \n",
      "221         0             0.75        0  \n",
      "369         1             0.67        0  \n",
      "320         1             0.75        0  \n",
      "265         0             0.71        0  \n",
      "\n",
      "[147 rows x 10 columns],      Serial No.  GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  \\\n",
      "25           26        340          120                  5  4.5   4.5  9.60   \n",
      "130         131        339          114                  5  4.0   4.5  9.76   \n",
      "20           21        312          107                  3  3.0   2.0  7.90   \n",
      "192         193        322          114                  5  4.5   4.0  8.94   \n",
      "124         125        301          106                  4  2.5   3.0  8.47   \n",
      "..          ...        ...          ...                ...  ...   ...   ...   \n",
      "8             9        302          102                  1  2.0   1.5  8.00   \n",
      "156         157        315          105                  3  2.0   2.5  8.34   \n",
      "123         124        308          108                  3  3.5   3.5  8.22   \n",
      "15           16        314          105                  3  3.5   2.5  8.30   \n",
      "125         126        300          100                  3  2.0   3.0  8.66   \n",
      "\n",
      "     Research  Chance of Admit  cluster  \n",
      "25          1             0.94        1  \n",
      "130         1             0.96        1  \n",
      "20          1             0.64        1  \n",
      "192         1             0.86        1  \n",
      "124         0             0.57        1  \n",
      "..        ...              ...      ...  \n",
      "8           0             0.50        1  \n",
      "156         0             0.70        1  \n",
      "123         0             0.61        1  \n",
      "15          0             0.54        1  \n",
      "125         1             0.64        1  \n",
      "\n",
      "[133 rows x 10 columns]]\n"
     ]
    }
   ],
   "source": [
    "print(X_train_clusters_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BVbD_sYQ88qB"
   },
   "source": [
    "# Building Linear Regression for our clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "BMwMKQEpLm2F"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "\"\"\"\n",
    "The number of clusters would be defined by the outcome of the silhouetter coefficient \n",
    "Set up the model of Linear Regression by exploring the different parameters: https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html\n",
    "train_clusters_df is a dataframe that contains both the true cluster values and the predicted cluster values. Feel free to change the variable name to something else if you have been following a different naming convention.\n",
    "\"\"\"\n",
    "\n",
    "#TO-DOfg\n",
    "# Set the number of clusters based on the silhouette coefficient analysis\n",
    "number_cluster = 2\n",
    "obj_cluster = []\n",
    "\n",
    "for i in range(number_cluster):\n",
    "    #TO-DO\n",
    "    # Initialize a Linear Regression object.\n",
    "    lr = LinearRegression()\n",
    "    #Get the specific X_train values according to their predicted clusters.\n",
    "    X_clustered_data = X_train_clusters_df[i][X_train_clusters_df[i].columns[0:8]]\n",
    "    #Get the specific Y_train values according to their predicted clusters.\n",
    "    Y_clustered_data = X_train_clusters_df[i][\"Chance of Admit\"]\n",
    "    obj_cluster.append(lr.fit(X_clustered_data, Y_clustered_data)) #Replace the underlines with the variable name you used to create the Linear Regression object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "iOF-lX3dL97-"
   },
   "outputs": [],
   "source": [
    "def predict_value(x_test, kmeans, cluster_linear):\n",
    "  \"\"\"\n",
    "  Input: \n",
    "  x_test is the test value that you wish to predict on.\n",
    "  kmeans is the kmeans object that you have finalized to predict on the test dataset.\n",
    "  cluster_linear is the list of fitted models on different clusters.\n",
    "\n",
    "  Return:\n",
    "  linear_pred - linear_pred will be type list with prediction values\n",
    "  clusters - clusters_pred will be the prediction of clusters using k means.\n",
    "\n",
    "  Follow these steps:\n",
    "  1. Predict clusters using K means object on the test data.\n",
    "  2. Predict regression values using Linear Regression list.\n",
    "  3. return both the predictions.\n",
    "\n",
    "  \"\"\"\n",
    "  linear_pred = []\n",
    "  clusters = kmeans.predict(x_test)\n",
    "  for i in range(0,x_test.shape[0]):\n",
    "    #print(x_test.iloc[[i]])\n",
    "    linear_pred.append(cluster_linear[clusters[i]].predict(x_test.iloc[[i]]))\n",
    "  return linear_pred, clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y-KOf0ncBvkN"
   },
   "source": [
    "# Final Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "TAYyCLx8Bcwb"
   },
   "outputs": [],
   "source": [
    "#Apply the clustering-based linear regression to the test set.\n",
    "Y_svr_k_means_pred, clusters_test = predict_value(X_test,kmeans,obj_cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([0.67722484]), array([0.77961651]), array([0.63249548]), array([0.55116358]), array([0.54110348]), array([0.66000388]), array([0.9509116]), array([0.92210144]), array([0.91580334]), array([0.66368536]), array([0.8183683]), array([0.87855199]), array([0.73664435]), array([0.59340214]), array([0.92128584]), array([0.91632721]), array([0.48077289]), array([0.76585254]), array([0.8147176]), array([0.77798748]), array([0.91712802]), array([0.76895964]), array([0.78377861]), array([0.74630533]), array([0.72222038]), array([0.70917961]), array([0.63542041]), array([0.94238505]), array([0.63223766]), array([0.73385595]), array([0.768258]), array([0.67107045]), array([0.76423616]), array([0.73237365]), array([0.64997462]), array([0.88591125]), array([0.51295312]), array([0.64836443]), array([0.79314342]), array([0.81765682]), array([0.93739937]), array([0.83999905]), array([0.76552104]), array([0.47666591]), array([0.68179324]), array([0.71060282]), array([0.69865061]), array([0.70738579]), array([0.58139321]), array([0.81639182]), array([0.83849088]), array([0.71090188]), array([0.90810942]), array([0.89130667]), array([0.50243364]), array([0.64869269]), array([0.75961044]), array([0.64059946]), array([0.68163252]), array([0.69766305]), array([0.59259611]), array([0.83650058]), array([0.77871794]), array([0.80804689]), array([0.68116744]), array([0.87902597]), array([0.83384139]), array([0.71677447]), array([0.87383797]), array([0.69164494]), array([0.94463937]), array([0.85106612]), array([0.79534852]), array([0.61395746]), array([0.71650245]), array([0.66747062]), array([0.95386828]), array([0.67572364]), array([0.73110994]), array([0.47297788]), array([0.74855501]), array([0.62631538]), array([0.67299809]), array([0.73331614]), array([0.81692592]), array([0.6461821]), array([0.66879293]), array([0.75196275]), array([0.88582103]), array([0.87072854]), array([0.97934207]), array([0.8415492]), array([0.76361324]), array([0.97411452]), array([0.70596664]), array([0.7623997]), array([0.71009233]), array([0.93069722]), array([0.64775132]), array([0.62963441]), array([0.46313849]), array([0.64456177]), array([0.63185446]), array([0.64811934]), array([0.66686416]), array([0.53218269]), array([0.8696257]), array([0.54265355]), array([0.6674232]), array([0.71719778]), array([0.46334314]), array([0.66636921]), array([0.71691153]), array([0.93954078]), array([0.52738772]), array([0.62573148]), array([0.5866836]), array([0.70312785]), array([0.58921207]), array([0.68636304])]\n"
     ]
    }
   ],
   "source": [
    "print(Y_svr_k_means_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "7hTtpG7j91JL"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test error (MSE)::  0.004189774794233369\n",
      "test error (MAE):  0.04486064110635149\n"
     ]
    }
   ],
   "source": [
    "print('test error (MSE):: ', get_mse(Y_test, np.array(Y_svr_k_means_pred).reshape(120,-1)))\n",
    "print('test error (MAE): ', get_mae(Y_test, np.array(Y_svr_k_means_pred).reshape(120,-1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}